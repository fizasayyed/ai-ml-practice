{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to paraphrase text using LLM\n",
    "def paraphrase_with_ollama(prompt_text, model='deepseek-r1:14b'):\n",
    "    url = 'http://localhost:11434/api/generate'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # For the prompt, I will be trying:\n",
    "    # 1. Trying style controlled paraphrasing (Ex: Try genz slang)\n",
    "    # 2. Multi phrase paraphrasing (Ex: Try 3 different paraphrases)\n",
    "    # 3. Noise aware or error tolerant paraphrasing (Ex: Try removing typos grammar etc)\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": f\"\"\"\n",
    "        Paraphrase the following sentence:\n",
    "\n",
    "        \\\"{prompt_text}\\\"\n",
    "\n",
    "        Make sure the meaning stays the same.\n",
    "        Adjust your response to be Genz slang.\n",
    "        Make sure the response is a single sentence and maximum 12 words.\n",
    "        Try to remove any typos or grammar errors.\n",
    "        \"\"\",\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "        result = response.json()\n",
    "        return result.get('response', 'No response found.')\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_sentence = \"Why do I have to attend this call. The information they are going to provide is pretty much what I already know. I can either ask them to provide me with the information or I can just skip this call. I dont think I will get anything new from this call.\"\n",
    "paraphrased_text = paraphrase_with_ollama(input_sentence)\n",
    "\n",
    "print(\"Original Sentence:\")\n",
    "print(input_sentence)\n",
    "print(\"\\nParaphrased Sentence:\")\n",
    "print(paraphrased_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
